From 4bc1eb2764f4c3599f4b8b9d1258696368bcf0e2 Mon Sep 17 00:00:00 2001
From: lu gao <lu.gao@lynxi.com>
Date: Fri, 19 Aug 2022 11:03:47 +0800
Subject: [PATCH] efficientnet-b0-torch-lyndetect-detect-lyncompile

---
 detect.py                                          | 48 ++++++++++++++
 efficientnet_pytorch/utils.py                      | 16 +++--
 lyncompile.py                                      | 32 +++++++++
 lyndetect.py                                       | 77 ++++++++++++++++++++++
 setup.py                                           |  2 +-
 .../convert_tf_to_pt/original_tf/utils.py          |  4 +-
 6 files changed, 170 insertions(+), 9 deletions(-)
 create mode 100755 detect.py
 create mode 100755 lyncompile.py
 create mode 100755 lyndetect.py

diff --git a/detect.py b/detect.py
new file mode 100755
index 0000000..92d20b3
--- /dev/null
+++ b/detect.py
@@ -0,0 +1,48 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+from efficientnet_pytorch import EfficientNet
+from torchvision import transforms
+from PIL import Image
+import json
+import torch
+import argparse
+
+def make_parser():
+    parser = argparse.ArgumentParser("efficientnet-b0 detect parser")
+    parser.add_argument("-n", "--model_name", type=str,
+                        default="efficientnet-b0", help="model name")
+    parser.add_argument("-m", "--image_path", type=str,
+                        default="examples/simple/img2.jpg", help="input image path")
+    parser.add_argument("-i", "--input_shape", type=str,
+                        default="1, 3, 224, 224", help="model input shape")
+    parser.add_argument("-l", "--label_path", type=str,
+                        default="examples/simple/labels_map.txt", help="label path")
+    parser.add_argument("-s", "--class_species", type=int,
+                        default=1000, help="class species number")
+
+    return parser
+
+if __name__ == "__main__":
+
+    args = make_parser().parse_args()
+    model = EfficientNet.from_pretrained(args.model_name)
+    # Preprocess image
+    input_shape = tuple(map(int, args.input_shape.split(",")))
+
+    tfms = transforms.Compose([transforms.Resize([input_shape[2], input_shape[2]]), transforms.ToTensor(),
+                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), ])
+    img = tfms(Image.open(args.image_path)
+               ).unsqueeze(0)
+
+    # Load ImageNet class names
+    labels_map = json.load(open(args.label_path))
+    labels_map = [labels_map[str(i)] for i in range(args.class_species)]
+
+    model.eval()
+    with torch.no_grad():
+        outputs_tensor = model(img)
+
+    for idx in torch.topk(outputs_tensor, k=5).indices.squeeze(0).tolist():
+        prob = torch.softmax(outputs_tensor, dim=1)[0, idx].item()
+        print('{label:<75} ({p:.2f}%)'.format(
+            label=labels_map[idx], p=prob*100))
\ No newline at end of file
diff --git a/efficientnet_pytorch/utils.py b/efficientnet_pytorch/utils.py
index 826a627..31a7bd3 100755
--- a/efficientnet_pytorch/utils.py
+++ b/efficientnet_pytorch/utils.py
@@ -62,13 +62,13 @@ else:
 
 # A memory-efficient implementation of Swish function
 class SwishImplementation(torch.autograd.Function):
-    @staticmethod
+    # @staticmethod
     def forward(ctx, i):
         result = i * torch.sigmoid(i)
         ctx.save_for_backward(i)
         return result
 
-    @staticmethod
+    # @staticmethod
     def backward(ctx, grad_output):
         i = ctx.saved_tensors[0]
         sigmoid_i = torch.sigmoid(i)
@@ -77,7 +77,9 @@ class SwishImplementation(torch.autograd.Function):
 
 class MemoryEfficientSwish(nn.Module):
     def forward(self, x):
-        return SwishImplementation.apply(x)
+        # return SwishImplementation.apply(x)
+        _SwishImplementation = SwishImplementation()
+        return _SwishImplementation.forward(x)
 
 
 def round_filters(filters, global_params):
@@ -363,7 +365,7 @@ class BlockDecoder(object):
        straight from the official TensorFlow repository.
     """
 
-    @staticmethod
+    # @staticmethod
     def _decode_block_string(block_string):
         """Get a block through a string notation of arguments.
 
@@ -398,7 +400,7 @@ class BlockDecoder(object):
             se_ratio=float(options['se']) if 'se' in options else None,
             id_skip=('noskip' not in block_string))
 
-    @staticmethod
+    # @staticmethod
     def _encode_block_string(block):
         """Encode a block to a string.
 
@@ -422,7 +424,7 @@ class BlockDecoder(object):
             args.append('noskip')
         return '_'.join(args)
 
-    @staticmethod
+    # @staticmethod
     def decode(string_list):
         """Decode a list of string notations to specify blocks inside the network.
 
@@ -438,7 +440,7 @@ class BlockDecoder(object):
             blocks_args.append(BlockDecoder._decode_block_string(block_string))
         return blocks_args
 
-    @staticmethod
+    # @staticmethod
     def encode(blocks_args):
         """Encode a list of BlockArgs to a list of strings.
 
diff --git a/lyncompile.py b/lyncompile.py
new file mode 100755
index 0000000..a4bd9a2
--- /dev/null
+++ b/lyncompile.py
@@ -0,0 +1,32 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+import lyngor as lyn
+import torch
+from efficientnet_pytorch import EfficientNet
+import argparse
+
+
+def make_parser():
+    parser = argparse.ArgumentParser("efficientnet-b0 compile parser")
+    parser.add_argument("-o", "--output_path", type=str,
+                        default="../convert_out", help="model output path")
+    parser.add_argument("-i", "--input_shape", type=str,
+                        default="1, 3, 224, 224", help="model input shape")
+    parser.add_argument("-n", "--model_name", type=str,
+                        default="efficientnet-b0", help="model name")
+
+    return parser
+
+
+if __name__ == "__main__":
+
+    args = make_parser().parse_args()
+    model = EfficientNet.from_pretrained(args.model_name)
+    model.eval()
+    with torch.no_grad():
+        dlmodel = lyn.DLModel()
+        input_shape = tuple(map(int, args.input_shape.split(",")))
+        dlmodel.load(model, model_type='Pytorch',
+                     inputs_dict={'inputs': input_shape})
+        builder = lyn.Builder(target='apu', is_map=True)
+        builder.build(dlmodel.graph, dlmodel.params, out_path=args.output_path)
diff --git a/lyndetect.py b/lyndetect.py
new file mode 100755
index 0000000..57a4949
--- /dev/null
+++ b/lyndetect.py
@@ -0,0 +1,77 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+from efficientnet_pytorch import EfficientNet
+from torchvision import transforms
+from PIL import Image
+import json
+import torch
+import argparse
+import lynpy
+
+
+def make_parser():
+    parser = argparse.ArgumentParser("efficientnet-b0 detect parser")
+    parser.add_argument(
+        "-m",
+        "--model",
+        type=str,
+        default="../convert_out/Net_0",
+        help="Input your lynor model."
+    )
+    parser.add_argument(
+        "-p",
+        "--image_path",
+        type=str,
+        default="examples/simple/img2.jpg",
+        help="input image path"
+    )
+    parser.add_argument(
+        "-i",
+        "--input_shape",
+        type=str,
+        default="1, 3, 224, 224",
+        help="model input shape"
+    )
+    parser.add_argument(
+        "-l",
+        "--label_path",
+        type=str,
+        default="examples/simple/labels_map.txt",
+        help="label path"
+    )
+    parser.add_argument(
+        "-s",
+        "--class_species",
+        type=int,
+        default=1000,
+        help="class species number"
+    )
+
+    return parser
+
+
+if __name__ == "__main__":
+
+    args = make_parser().parse_args()
+    # Preprocess image
+    input_shape = tuple(map(int, args.input_shape.split(",")))
+
+    tfms = transforms.Compose([transforms.Resize([input_shape[2], input_shape[2]]), transforms.ToTensor(),
+                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), ])
+    img = tfms(Image.open(args.image_path)
+               ).unsqueeze(0)
+
+    # Load ImageNet class names
+    labels_map = json.load(open(args.label_path))
+    labels_map = [labels_map[str(i)] for i in range(args.class_species)]
+
+    model = lynpy.Model(path=args.model)
+    lyn_in = model.input_tensor().from_numpy(img.numpy()).apu()
+    model(lyn_in)
+    outputs = model.output_list()[0][0].cpu()
+    outputs_tensor = torch.tensor(outputs.numpy())
+
+    for idx in torch.topk(outputs_tensor, k=5).indices.squeeze(0).tolist():
+        prob = torch.softmax(outputs_tensor, dim=1)[0, idx].item()
+        print('{label:<75} ({p:.2f}%)'.format(
+            label=labels_map[idx], p=prob*100))
diff --git a/setup.py b/setup.py
index eb8d95a..68d7989 100644
--- a/setup.py
+++ b/setup.py
@@ -61,7 +61,7 @@ class UploadCommand(Command):
     description = 'Build and publish the package.'
     user_options = []
 
-    @staticmethod
+    # @staticmethod
     def status(s):
         """Prints things in bold."""
         print('\033[1m{0}\033[0m'.format(s))
diff --git a/tf_to_pytorch/convert_tf_to_pt/original_tf/utils.py b/tf_to_pytorch/convert_tf_to_pt/original_tf/utils.py
index 61782ea..f547e89 100644
--- a/tf_to_pytorch/convert_tf_to_pt/original_tf/utils.py
+++ b/tf_to_pytorch/convert_tf_to_pt/original_tf/utils.py
@@ -254,7 +254,9 @@ class EvalCkptDriver(object):
       ema = tf.train.ExponentialMovingAverage(decay=0.0)
       ema_vars = get_ema_vars()
       var_dict = ema.variables_to_restore(ema_vars)
-      ema_assign_op = ema.apply(ema_vars)
+      # ema_assign_op = ema.apply(ema_vars)
+      _ema_assign_op = ema()
+      ema_assign_op = _ema_assign_op.forward(ema_vars)
     else:
       var_dict = get_ema_vars()
       ema_assign_op = None
-- 
2.7.4


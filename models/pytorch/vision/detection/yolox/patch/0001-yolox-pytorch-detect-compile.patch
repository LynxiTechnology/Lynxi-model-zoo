From 199f9d9bce479d5c43186c306754d8d56fda1a57 Mon Sep 17 00:00:00 2001
From: lu gao <lu.gao@lynxi.com>
Date: Fri, 10 Jun 2022 10:04:06 +0800
Subject: [PATCH] yolox-pytorch-detect-compile

---
 lyncompile.py | 32 +++++++++++++++++++++
 lyndetect.py  | 92 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 124 insertions(+)
 create mode 100755 lyncompile.py
 create mode 100644 lyndetect.py

diff --git a/lyncompile.py b/lyncompile.py
new file mode 100755
index 0000000..c18adfc
--- /dev/null
+++ b/lyncompile.py
@@ -0,0 +1,32 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+import argparse
+import lyngor as lyn
+from yolox.exp import get_exp
+import torch
+
+def make_parser():
+    parser = argparse.ArgumentParser("YOLOX-s compile parser")
+    parser.add_argument("-m", "--model_path", type=str, default="../yolox_s.pth", help="model path")
+    parser.add_argument("-o", "--output_path", type=str, default="../convert_out", help="model output path")
+    parser.add_argument("-i", "--input_shape", type=str, default="1, 3, 640, 640", help="model input shape")
+    parser.add_argument("-n", "--model_name", type=str, default="yolox-s", help="model name")
+    
+    return parser
+
+if __name__ == "__main__":
+ 
+    args = make_parser().parse_args()
+    exp = get_exp(exp_name=args.model_name)
+    model = exp.get_model()
+    model.eval()
+    ckpt = torch.load(args.model_path, map_location="cpu")
+    model.load_state_dict(ckpt["model"])
+    model.head.decode_in_inference = False
+
+    dlmodel = lyn.DLModel()
+    input_shape = tuple(map(int, args.input_shape.split(",")))
+    dlmodel.load(model, model_type='Pytorch',
+                inputs_dict={'images': input_shape})
+    builder = lyn.Builder(target='apu', is_map=True)
+    builder.build(dlmodel.graph, dlmodel.params, out_path=args.output_path)
\ No newline at end of file
diff --git a/lyndetect.py b/lyndetect.py
new file mode 100644
index 0000000..1565577
--- /dev/null
+++ b/lyndetect.py
@@ -0,0 +1,92 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+import argparse
+import os
+import cv2
+import numpy as np
+from yolox.data.data_augment import preproc as preprocess
+from yolox.data.datasets import COCO_CLASSES
+from yolox.utils import mkdir, multiclass_nms, demo_postprocess, vis
+import lynpy
+import time
+from loguru import logger
+
+def make_parser():
+    parser = argparse.ArgumentParser("inference sample")
+    parser.add_argument(
+        "-m",
+        "--model",
+        type=str,
+        default="../convert_out/Net_0",
+        help="Input your lynor model.",
+    )
+    parser.add_argument(
+        "-i",
+        "--image_path",
+        type=str,
+        default='./assets/dog.jpg',
+        help="Path to your input image.",
+    )
+    parser.add_argument(
+        "-o",
+        "--output_dir",
+        type=str,
+        default='./demo_output',
+        help="Path to your output directory.",
+    )
+    parser.add_argument(
+        "-s",
+        "--score_thr",
+        type=float,
+        default=0.3,
+        help="Score threshould to filter the result.",
+    )
+    parser.add_argument(
+        "--input_shape",
+        type=str,
+        default="640,640",
+        help="Specify an input shape for inference.",
+    )
+    parser.add_argument(
+        "--with_p6",
+        action="store_true",
+        help="Whether your model uses p6 in FPN/PAN.",
+    )
+    return parser
+
+if __name__ == '__main__':
+    args = make_parser().parse_args()
+    input_shape = tuple(map(int, args.input_shape.split(',')))
+    origin_img = cv2.imread(args.image_path)
+    img, ratio = preprocess(origin_img, input_shape)
+
+    lyn_model = lynpy.Model(path=args.model)
+    # Inference
+    for i in range(10):
+        t0 = time.time()
+        lyn_in = lyn_model.input_tensor().from_numpy(img).apu()
+        lyn_model(lyn_in)
+        output = lyn_model.output_list()[0][0].cpu()
+        iTime = time.time() - t0
+        logger.info("Infer time: {:.4f}s, {:.2f}fps".format(iTime, 1/iTime))
+
+    output = output.numpy()
+    predictions = demo_postprocess(output, input_shape, p6=args.with_p6)[0]
+    boxes = predictions[:, :4]
+    scores = predictions[:, 4:5] * predictions[:, 5:]
+
+    boxes_xyxy = np.ones_like(boxes)
+    boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2]/2.
+    boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3]/2.
+    boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2]/2.
+    boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3]/2.
+    boxes_xyxy /= ratio
+    dets = multiclass_nms(boxes_xyxy, scores, nms_thr=0.45, score_thr=0.1)
+    if dets is not None:
+        final_boxes, final_scores, final_cls_inds = dets[:, :4], dets[:, 4], dets[:, 5]
+        origin_img = vis(origin_img, final_boxes, final_scores, final_cls_inds,
+                         conf=args.score_thr, class_names=COCO_CLASSES)
+
+    mkdir(args.output_dir)
+    output_path = os.path.join(args.output_dir, os.path.basename(args.image_path))
+    cv2.imwrite(output_path, origin_img)
-- 
2.7.4

